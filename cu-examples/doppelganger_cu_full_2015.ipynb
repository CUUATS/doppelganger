{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Doppelganger!\n",
    "Welcome to the Doppelganger example. If you have not already done so, please see the [README document](https://github.com/sidewalklabs/doppelganger/blob/master/README.md) for installation instructions and information on what Doppelganger is doing under the hood. For a simplified walkthrough, take a look at [doppelganger_example_simple](./doppelganger_example_simple.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What's in this Example?\n",
    "This workbook acts on a single PUMA and carries out the following tasks: \n",
    "1. Builds household- and person-specific Bayesian Networks for an individual PUMA; \n",
    "2. Allocates PUMS households to an individual PUMA consistent with subjectively-weighted marginal controls; and,\n",
    "3. Replaces the drawn PUMS population with synthetic people created by moving through and person-specific Bayesian Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Housekeeping\n",
    "Before we get going, let's take care of some housekeeping tasks to make your Doppelganger Example experience as seamless as possible. \n",
    "\n",
    "We have included a cross-walk between PUMAs and Census tracts that we'll use later. Please navigate to this file and unzip it in the same directory. The file is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ./examples/sample_data/2010_puma_tract_mapping.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The example operates on a single PUMA in California (`00106`). In Step 01 below, you'll see that we have already extracted PUMS data for this PUMA, so we'd recommend that you do not change to your favorite PUMA just yet (here's a set of [reference maps for California](https://www.census.gov/geo/maps-data/maps/2010puma/st06_ca.html) -- all states are available). But once you get comfortable with the tools, download the PUMS data for the PUMA of your choice, and go for it. \n",
    "\n",
    "Champaign County PUMA=02100 https://www2.census.gov/geo/maps/dc10map/PUMA_RefMap/st17_il/puma1702100/DC10PUMA1702100_000.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PUMA = '02100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Later in the example we grab some Census data using the [Census API](https://www.census.gov/developers/). Enter your Census key below (if you need one, you can get one for free [here](http://api.census.gov/data/key_signup.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MY_CENSUS_KEY = 'ae3b01908de23e11ad28eb2f8837b14eed24345c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This example will generate a variety of output. Please specify where you'd like this data written to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'L:\\Urbansim\\doppelganger-master\\doppelganger-CU\\cu_output_2015'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Configuration\n",
    "We'll need to configure your computing environment and load in the configuration file before getting started. \n",
    "### Import the relevant Doppelganger Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from doppelganger import (\n",
    "    allocation,\n",
    "    Configuration,\n",
    "    HouseholdAllocator,\n",
    "    PumsData,\n",
    "    SegmentedData,\n",
    "    BayesianNetworkModel,\n",
    "    Population,\n",
    "    Preprocessor,\n",
    "    Marginals,\n",
    "    inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load the Doppelganger example configuration file\n",
    "This file does the following three things:\n",
    "1. Defines person-specific variables in `person_fields`. In the example, you'll see `age`, `sex`, and `individual_income`. These variables are mapped to the PUMS variables in `inputs.py`. For example, `age` in Doppelganger is mapped to the PUMS variable `agep`. To use other variables from the PUMS with Doppelganger, you'll need to map their relationships in `inputs.py` and specify them here. \n",
    "2. Defines household-specific variables in `household_fields`. In the example, you'll see `household_income` and `num_vehicles`. As with the person-specific variables, you'll need to modify `inputs.py` to use other variables in Doppelganger.\n",
    "3. Defines procedures to process input variables into bins in `preprocessing`.\n",
    "4. Defines the structure of the household and person Bayesian Networks in `network_config_files`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "configuration = Configuration.from_file('cu-sample_data/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With the `configuration` in hand, we can create a `preprocessor` object that will create methods to apply to the household and person PUMS data. In the current configuration, the `preprocessor` bins the individual income variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor.from_config(configuration.preprocessing_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 01: Let's Build some Bayesian Networks!\n",
    "Bayesian Networks are built using the specification (`network_config_files`) in the configuration file and cleaned PUMS data. Up first: let's read in and clean the PUMS data.\n",
    "\n",
    "### Data reads\n",
    "#### Household Data\n",
    "The fields we need from the household data is the union of those defined in the `allocation.DEFAULT_HOUSEHOLD_FIELDS` and those defined `household_categories` section of the configuration file. The raw/dirty data collected for our example PUMA is available [here](https://www.census.gov/programs-surveys/acs/data/pums.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "household_fields = tuple(set(\n",
    "    field.name for field in allocation.DEFAULT_HOUSEHOLD_FIELDS).union(\n",
    "        set(configuration.household_fields)\n",
    "))\n",
    "\n",
    "households_data = PumsData.from_csv('cu-sample_data/Household_2015_dirty_5year.csv').clean(\n",
    "    household_fields, preprocessor, puma=PUMA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Person Data\n",
    "The `allocation.DEFAULT_PERSON_FIELDS` defines a set of fields that can be used to create the `persons_data`; we take the union of these defaults with those defined in the `person_categories` section of the configuration file. This data is then extracted from the raw/dirty PUMS data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "persons_fields = tuple(set(\n",
    "    field.name for field in allocation.DEFAULT_PERSON_FIELDS).union(\n",
    "        set(configuration.person_fields)\n",
    "))\n",
    "persons_data = PumsData.from_csv('cu-sample_data/Population_2015_dirty_5year.csv').clean(\n",
    "    persons_fields, preprocessor, puma=PUMA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bayesian Networks\n",
    "The example below shows the training of a person-level model. It requires the following inputs:\n",
    "1. The `persons_data`, which was created in the previous step;\n",
    "2. A list of variables you want to consider in the training -- taken here from our configuration file; and,\n",
    "3. An optional weight if you want to weight the records (in the example, we use the PUMS variable `pwgtp`, which is defined in `inputs.py`. \n",
    "\n",
    "Once the training data is prepared, the training needs the `person_structure`, which is defined as in the `network_config_files` section of the configuration file, and the `person_fields`, which are also defined in the configuration file. The example `person_structure` specifies a network with three nodes (`age`, `sex`, and `income`) and two edges (`age` --> `income`, and `sex` --> `income`). The example `household_structure` specifies a network with three nodes (`num_people`, `household_income`, and `num_vehicles`) and three edges (`num_people` --> `household_income`, `num_people` --> `num_vehicles`, and `household_income` --> `num_vehicles`).\n",
    "\n",
    "<img src=\"./images/structure.png\" alt=\"Structure Image\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "person_training_data = SegmentedData.from_data(\n",
    "    persons_data,\n",
    "    list(configuration.person_fields),\n",
    "    weight_field = inputs.PERSON_WEIGHT.name\n",
    ")\n",
    "person_model = BayesianNetworkModel.train(\n",
    "    person_training_data,\n",
    "    configuration.person_structure,\n",
    "    configuration.person_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Bayesian Networks can also be fully segmented. In the below example, we rebuild the networks, fully segmented by age category via the `segmenter` functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "person_segmentation = lambda x: x[inputs.AGE.name]\n",
    "\n",
    "person_training_data = SegmentedData.from_data(\n",
    "    persons_data,\n",
    "    list(configuration.person_fields),\n",
    "    inputs.PERSON_WEIGHT.name,\n",
    "    person_segmentation\n",
    ")\n",
    "person_model = BayesianNetworkModel.train(\n",
    "    person_training_data,\n",
    "    configuration.person_structure,\n",
    "    configuration.person_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Bayesian Network can be written to disk and read from disk as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "person_model_filename = os.path.join(output_dir, 'person_model.json')\n",
    "person_model.write(person_model_filename)\n",
    "person_model_reloaded = BayesianNetworkModel.from_file(person_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Following the same steps as above, you can also build a household network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "household_segmenter = lambda x: x[inputs.NUM_PEOPLE.name]\n",
    "\n",
    "household_training_data = SegmentedData.from_data(\n",
    "    households_data,\n",
    "    list(configuration.household_fields),\n",
    "    inputs.HOUSEHOLD_WEIGHT.name,\n",
    "    household_segmenter,\n",
    ")\n",
    "household_model = BayesianNetworkModel.train(\n",
    "    household_training_data,\n",
    "    configuration.household_structure,\n",
    "    configuration.household_fields\n",
    ")\n",
    "\n",
    "household_model_filename = os.path.join(output_dir, 'household_model.json')\n",
    "household_model.write(household_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 02: Allocate PUMS households to the PUMA\n",
    "The sample data comes with a set of marginals that can be used in the allocation step. This file is named `sample_data/marginals_02100.csv`. To demonstrate how marginals can be created, we create them here. Note that this step will take a few minutes. If you want to skip it, use the `controls = Marginals.from_csv('sample_data/marginals_02100.csv')` call in the subsequent code box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching tract 020100\n",
      "Fetching tract 020200\n",
      "Fetching tract 020300\n",
      "Fetching tract 020400\n",
      "Fetching tract 020500\n",
      "Fetching tract 020600\n",
      "Fetching tract 020700\n",
      "Fetching tract 020801\n",
      "Fetching tract 020802\n",
      "Fetching tract 020900\n",
      "Fetching tract 021000\n",
      "Fetching tract 021100\n",
      "Fetching tract 030100\n",
      "Fetching tract 030200\n",
      "Fetching tract 030300\n",
      "Fetching tract 030400\n",
      "Fetching tract 030500\n",
      "Fetching tract 030600\n",
      "Fetching tract 030701\n",
      "Fetching tract 030702\n",
      "Fetching tract 030800\n",
      "Fetching tract 030901\n",
      "Fetching tract 030902\n",
      "Fetching tract 031000\n",
      "Fetching tract 031100\n",
      "Fetching tract 031200\n",
      "Fetching tract 031300\n",
      "Fetching tract 780800\n",
      "Fetching tract 781000\n",
      "Fetching tract 781100\n",
      "Fetching tract 781200\n",
      "Fetching tract 000300\n",
      "Fetching tract 005101\n",
      "Fetching tract 005408\n",
      "Fetching tract 005501\n",
      "Fetching tract 005504\n",
      "Fetching tract 005604\n",
      "Fetching tract 005700\n",
      "Fetching tract 005800\n",
      "Fetching tract 005901\n",
      "Fetching tract 006000\n",
      "Fetching tract 170100\n",
      "Fetching tract 170200\n",
      "Fetching tract 170303\n",
      "Fetching tract 170304\n",
      "Fetching tract 170305\n",
      "Fetching tract 170306\n",
      "Fetching tract 170402\n",
      "Fetching tract 170403\n",
      "Fetching tract 170404\n",
      "Fetching tract 170405\n",
      "Fetching tract 170406\n",
      "Fetching tract 170501\n",
      "Fetching tract 170502\n",
      "Fetching tract 170503\n",
      "Fetching tract 170601\n",
      "Fetching tract 170602\n",
      "Fetching tract 170603\n",
      "Fetching tract 170700\n",
      "Fetching tract 170801\n",
      "Fetching tract 170802\n",
      "Fetching tract 000200\n",
      "Fetching tract 000301\n",
      "Fetching tract 000302\n",
      "Fetching tract 000401\n",
      "Fetching tract 000402\n",
      "Fetching tract 000500\n",
      "Fetching tract 000700\n",
      "Fetching tract 000800\n",
      "Fetching tract 000901\n",
      "Fetching tract 000902\n",
      "Fetching tract 001000\n",
      "Fetching tract 001100\n",
      "Fetching tract 001201\n",
      "Fetching tract 001203\n",
      "Fetching tract 001204\n",
      "Fetching tract 001205\n",
      "Fetching tract 001206\n",
      "Fetching tract 001301\n",
      "Fetching tract 001302\n",
      "Fetching tract 001400\n",
      "Fetching tract 005300\n",
      "Fetching tract 005401\n",
      "Fetching tract 005402\n",
      "Fetching tract 005500\n",
      "Fetching tract 005600\n",
      "Fetching tract 005701\n",
      "Fetching tract 005702\n",
      "Fetching tract 005800\n",
      "Fetching tract 005900\n",
      "Fetching tract 006000\n",
      "Fetching tract 010100\n",
      "Fetching tract 010204\n",
      "Fetching tract 010300\n",
      "Fetching tract 010400\n",
      "Fetching tract 010500\n",
      "Fetching tract 010601\n",
      "Fetching tract 010603\n",
      "Fetching tract 010604\n",
      "Fetching tract 010700\n",
      "Fetching tract 010800\n",
      "Fetching tract 010900\n",
      "Fetching tract 011000\n",
      "Fetching tract 011100\n",
      "Fetching tract 974600\n",
      "Fetching tract 974700\n",
      "Fetching tract 974800\n",
      "Fetching tract 974900\n",
      "Fetching tract 510100\n",
      "Fetching tract 510201\n",
      "Fetching tract 510202\n",
      "Fetching tract 510300\n",
      "Fetching tract 510401\n",
      "Fetching tract 510402\n",
      "Fetching tract 510500\n",
      "Fetching tract 510600\n",
      "Fetching tract 510701\n",
      "Fetching tract 510702\n",
      "Fetching tract 510800\n",
      "Fetching tract 510900\n",
      "Fetching tract 511000\n",
      "Fetching tract 956000\n",
      "Fetching tract 956100\n",
      "Fetching tract 956200\n",
      "Fetching tract 956300\n",
      "Fetching tract 956400\n",
      "Fetching tract 956500\n",
      "Fetching tract 956600\n",
      "Fetching tract 190100\n",
      "Fetching tract 190200\n",
      "Fetching tract 190300\n",
      "Fetching tract 190400\n",
      "Fetching tract 190500\n",
      "Fetching tract 970100\n",
      "Fetching tract 970200\n",
      "Fetching tract 970300\n",
      "Fetching tract 290100\n",
      "Fetching tract 290200\n",
      "Fetching tract 290300\n",
      "Fetching tract 290400\n",
      "Fetching tract 290500\n",
      "Fetching tract 040100\n",
      "Fetching tract 040201\n",
      "Fetching tract 040202\n",
      "Fetching tract 040301\n",
      "Fetching tract 040302\n",
      "Fetching tract 960100\n",
      "Fetching tract 960200\n",
      "Fetching tract 960300\n",
      "Fetching tract 960400\n",
      "Fetching tract 490100\n",
      "Fetching tract 490200\n",
      "Fetching tract 490300\n",
      "Fetching tract 490400\n",
      "Fetching tract 490500\n",
      "Fetching tract 490600\n",
      "Fetching tract 021200\n",
      "Fetching tract 021400\n",
      "Fetching tract 021501\n",
      "Fetching tract 021502\n",
      "Fetching tract 021602\n",
      "Fetching tract 021603\n",
      "Fetching tract 021701\n",
      "Fetching tract 021702\n",
      "Fetching tract 030100\n",
      "Fetching tract 030200\n",
      "Fetching tract 030300\n",
      "Fetching tract 030401\n",
      "Fetching tract 030402\n",
      "Fetching tract 030501\n",
      "Fetching tract 030502\n",
      "Fetching tract 030601\n",
      "Fetching tract 030602\n",
      "Fetching tract 030700\n",
      "Fetching tract 030800\n",
      "Fetching tract 030900\n",
      "Fetching tract 031000\n",
      "Fetching tract 031100\n",
      "Fetching tract 031200\n",
      "Fetching tract 031300\n",
      "Fetching tract 031400\n",
      "Fetching tract 031601\n",
      "Fetching tract 031602\n",
      "Fetching tract 031700\n",
      "Fetching tract 031800\n",
      "Fetching tract 031900\n",
      "Fetching tract 960100\n",
      "Fetching tract 960200\n",
      "Fetching tract 960300\n",
      "Fetching tract 960400\n",
      "Fetching tract 930100\n",
      "Fetching tract 930200\n",
      "Fetching tract 930300\n",
      "Fetching tract 930400\n",
      "Fetching tract 930500\n",
      "Fetching tract 930600\n",
      "Fetching tract 930700\n",
      "Fetching tract 970100\n",
      "Fetching tract 970200\n",
      "Fetching tract 970300\n",
      "Fetching tract 970400\n",
      "Fetching tract 060101\n",
      "Fetching tract 060102\n",
      "Fetching tract 060200\n",
      "Fetching tract 060300\n",
      "Fetching tract 060400\n",
      "Fetching tract 060502\n",
      "Fetching tract 060503\n",
      "Fetching tract 060504\n",
      "Fetching tract 060600\n",
      "Fetching tract 920101\n",
      "Fetching tract 920102\n",
      "Fetching tract 920103\n",
      "Fetching tract 920200\n",
      "Fetching tract 920300\n",
      "Fetching tract 920400\n",
      "Fetching tract 000101\n",
      "Fetching tract 000102\n",
      "Fetching tract 000201\n",
      "Fetching tract 000202\n",
      "Fetching tract 000300\n",
      "Fetching tract 000401\n",
      "Fetching tract 000402\n",
      "Fetching tract 000500\n",
      "Fetching tract 000600\n",
      "Fetching tract 000700\n",
      "Fetching tract 000800\n",
      "Fetching tract 000900\n",
      "Fetching tract 001000\n",
      "Fetching tract 001100\n",
      "Fetching tract 001201\n",
      "Fetching tract 001202\n",
      "Fetching tract 001300\n",
      "Fetching tract 001400\n",
      "Fetching tract 001500\n",
      "Fetching tract 001600\n",
      "Fetching tract 001700\n",
      "Fetching tract 990000\n",
      "Fetching tract 270100\n",
      "Fetching tract 270200\n",
      "Fetching tract 270300\n",
      "Fetching tract 270400\n",
      "Fetching tract 460100\n",
      "Fetching tract 460200\n",
      "Fetching tract 460300\n",
      "Fetching tract 460400\n",
      "Fetching tract 460500\n",
      "Fetching tract 460600\n",
      "Fetching tract 480100\n",
      "Fetching tract 480200\n",
      "Fetching tract 480300\n",
      "Fetching tract 480400\n",
      "Fetching tract 790100\n",
      "Fetching tract 790200\n",
      "Fetching tract 790300\n",
      "Fetching tract 790400\n",
      "Fetching tract 790500\n",
      "Fetching tract 790600\n",
      "Fetching tract 900100\n",
      "Fetching tract 900200\n",
      "Fetching tract 900300\n",
      "Fetching tract 105100\n",
      "Fetching tract 105200\n",
      "Fetching tract 105300\n",
      "Fetching tract 105400\n",
      "Fetching tract 105500\n",
      "Fetching tract 105600\n",
      "Fetching tract 460100\n",
      "Fetching tract 460200\n",
      "Fetching tract 460300\n",
      "Fetching tract 460400\n",
      "Fetching tract 460500\n",
      "Fetching tract 570100\n",
      "Fetching tract 570200\n",
      "Fetching tract 570300\n",
      "Fetching tract 950100\n",
      "Fetching tract 950200\n",
      "Fetching tract 950300\n",
      "Fetching tract 040101\n",
      "Fetching tract 040102\n",
      "Fetching tract 040201\n",
      "Fetching tract 040203\n",
      "Fetching tract 040204\n",
      "Fetching tract 040300\n",
      "Fetching tract 040400\n",
      "Fetching tract 040500\n",
      "Fetching tract 040600\n",
      "Fetching tract 040700\n",
      "Fetching tract 040800\n",
      "Fetching tract 040900\n",
      "Fetching tract 041000\n",
      "Fetching tract 041100\n",
      "Fetching tract 041300\n",
      "Fetching tract 041400\n",
      "Fetching tract 041500\n",
      "Fetching tract 041600\n",
      "Fetching tract 041700\n",
      "Fetching tract 041800\n",
      "Fetching tract 041900\n",
      "Fetching tract 042000\n",
      "Fetching tract 042100\n",
      "Fetching tract 042200\n",
      "Fetching tract 042500\n",
      "Fetching tract 042600\n",
      "Fetching tract 042700\n",
      "Fetching tract 042900\n",
      "Fetching tract 990000\n",
      "Fetching tract 470100\n",
      "Fetching tract 470200\n",
      "Fetching tract 470300\n",
      "Fetching tract 470400\n",
      "Fetching tract 470500\n",
      "Fetching tract 960100\n",
      "Fetching tract 960200\n",
      "Fetching tract 960300\n",
      "Fetching tract 960400\n",
      "Fetching tract 950101\n",
      "Fetching tract 950102\n",
      "Fetching tract 950300\n",
      "Fetching tract 950400\n",
      "Fetching tract 950600\n",
      "Fetching tract 950700\n",
      "Fetching tract 950800\n",
      "Fetching tract 950901\n",
      "Fetching tract 950902\n",
      "Fetching tract 951000\n",
      "Fetching tract 951100\n",
      "Fetching tract 460100\n",
      "Fetching tract 460200\n",
      "Fetching tract 460300\n",
      "Fetching tract 460400\n",
      "Fetching tract 460500\n",
      "Fetching tract 000100\n",
      "Fetching tract 000200\n",
      "Fetching tract 000300\n",
      "Fetching tract 000401\n",
      "Fetching tract 000402\n",
      "Fetching tract 000500\n",
      "Fetching tract 000600\n",
      "Fetching tract 000700\n",
      "Fetching tract 000800\n",
      "Fetching tract 000900\n",
      "Fetching tract 001000\n",
      "Fetching tract 001100\n",
      "Fetching tract 001200\n",
      "Fetching tract 001300\n",
      "Fetching tract 001400\n",
      "Fetching tract 001500\n",
      "Fetching tract 001600\n",
      "Fetching tract 001700\n",
      "Fetching tract 001800\n",
      "Fetching tract 001900\n",
      "Fetching tract 002000\n",
      "Fetching tract 080100\n",
      "Fetching tract 080201\n",
      "Fetching tract 080202\n",
      "Fetching tract 080300\n",
      "Fetching tract 080401\n",
      "Fetching tract 080402\n",
      "Fetching tract 080501\n",
      "Fetching tract 080502\n",
      "Fetching tract 080600\n",
      "Fetching tract 080700\n",
      "Fetching tract 080800\n",
      "Fetching tract 080900\n",
      "Fetching tract 081000\n",
      "Fetching tract 081101\n",
      "Fetching tract 081102\n",
      "Fetching tract 020100\n",
      "Fetching tract 020201\n",
      "Fetching tract 020202\n",
      "Fetching tract 020301\n",
      "Fetching tract 020302\n",
      "Fetching tract 020500\n",
      "Fetching tract 020600\n",
      "Fetching tract 020801\n",
      "Fetching tract 020802\n",
      "Fetching tract 020900\n",
      "Fetching tract 021000\n",
      "Fetching tract 021100\n",
      "Fetching tract 021201\n",
      "Fetching tract 021202\n",
      "Fetching tract 021203\n",
      "Fetching tract 021301\n",
      "Fetching tract 021302\n",
      "Fetching tract 021400\n",
      "Fetching tract 970100\n",
      "Fetching tract 970200\n",
      "Fetching tract 970300\n",
      "Fetching tract 970400\n",
      "Fetching tract 970500\n",
      "Fetching tract 970600\n",
      "Fetching tract 970700\n",
      "Fetching tract 970800\n",
      "Fetching tract 970901\n",
      "Fetching tract 970902\n",
      "Fetching tract 970100\n",
      "Fetching tract 970200\n",
      "Fetching tract 970300\n",
      "Fetching tract 970400\n",
      "Fetching tract 970500\n",
      "Fetching tract 970600\n",
      "Fetching tract 970700\n",
      "Fetching tract 970800\n",
      "Fetching tract 970900\n",
      "Fetching tract 971000\n",
      "Fetching tract 971100\n",
      "Fetching tract 915400\n",
      "Fetching tract 915500\n",
      "Fetching tract 915600\n",
      "Fetching tract 915700\n",
      "Fetching tract 915800\n",
      "Fetching tract 915900\n",
      "Fetching tract 916000\n",
      "Fetching tract 916100\n",
      "Fetching tract 916200\n",
      "Fetching tract 916300\n",
      "Fetching tract 916400\n",
      "Fetching tract 916500\n",
      "Fetching tract 916600\n",
      "Fetching tract 000100\n",
      "Fetching tract 000200\n",
      "Fetching tract 000300\n",
      "Fetching tract 000500\n",
      "Fetching tract 000600\n",
      "Fetching tract 000700\n",
      "Fetching tract 001200\n",
      "Fetching tract 010100\n",
      "Fetching tract 010200\n",
      "Fetching tract 010300\n",
      "Fetching tract 010500\n",
      "Fetching tract 010600\n",
      "Fetching tract 010700\n",
      "Fetching tract 010801\n",
      "Fetching tract 011000\n",
      "Fetching tract 011100\n",
      "Fetching tract 011200\n",
      "Fetching tract 011300\n",
      "Fetching tract 011400\n",
      "Fetching tract 011500\n",
      "Fetching tract 011600\n",
      "Fetching tract 011700\n",
      "Fetching tract 011800\n",
      "Fetching tract 011900\n",
      "Fetching tract 012000\n",
      "Fetching tract 012100\n",
      "Fetching tract 012200\n",
      "Fetching tract 012300\n",
      "Fetching tract 012400\n",
      "Fetching tract 012500\n",
      "Fetching tract 012600\n",
      "Fetching tract 012700\n",
      "Fetching tract 012800\n",
      "Fetching tract 012900\n",
      "Fetching tract 013000\n",
      "Fetching tract 013100\n",
      "Fetching tract 013200\n",
      "Fetching tract 013300\n",
      "Fetching tract 013400\n",
      "Fetching tract 013500\n",
      "Fetching tract 013600\n",
      "Fetching tract 013700\n",
      "Fetching tract 953000\n",
      "Fetching tract 953100\n",
      "Fetching tract 953200\n",
      "Fetching tract 955000\n",
      "Fetching tract 955100\n",
      "Fetching tract 955200\n",
      "Fetching tract 955300\n",
      "Fetching tract 050101\n",
      "Fetching tract 050102\n",
      "Fetching tract 050201\n",
      "Fetching tract 050202\n",
      "Fetching tract 050301\n",
      "Fetching tract 050302\n",
      "Fetching tract 960100\n",
      "Fetching tract 960200\n",
      "Fetching tract 960300\n",
      "Fetching tract 975000\n",
      "Fetching tract 975100\n",
      "Fetching tract 975200\n",
      "Fetching tract 975300\n",
      "Fetching tract 975401\n",
      "Fetching tract 975402\n",
      "Fetching tract 060101\n",
      "Fetching tract 060102\n",
      "Fetching tract 060200\n"
     ]
    }
   ],
   "source": [
    "new_marginal_filename = os.path.join(output_dir, 'marginals_02100.csv')\n",
    "\n",
    "with open('cu-sample_data/2010_puma_tract_mapping.txt') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    marginals = Marginals.from_census_data(\n",
    "        csv_reader, MY_CENSUS_KEY, pumas=[PUMA]\n",
    "    )\n",
    "    marginals.write(new_marginal_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "controls = Marginals.from_csv('cu-sample_data/marginals_02100.csv') # use this one if you want to skip previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With the above marginal controls, the methods in `allocation.py` allocate discrete PUMS households to the subject PUMA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "allocator = HouseholdAllocator.from_cleaned_data(controls, households_data, persons_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 03: Replace the PUMS Persons with Synthetic Persons created from the Bayesian Network\n",
    "It may be convenient to replace the source population with a synthetic population -- to add heterogeniety to the synthetic population or to obscure the source data set. In the below example we generate a set of persons and households using the `allocator` (the PUMS persons allocated to tracts), the Bayesian Networks (`person_model`, `household_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = Population.generate(\n",
    "    allocator, person_model, household_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the people and households as Pandas DataFrames and work with them directly. Households and people are unique by `(tract, serial_number, repeat_index)`. `serial_number` is the PUMS serialno for the household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tract  serial_number  repeat_index    age sex individual_income\n",
      "148    200  2011000004688             0    65+   F               <=0\n",
      "268    200  2011000008273             0  35-64   F       40000-80000\n",
      "312    200  2011000008273             0   0-17   F               <=0\n",
      "356    200  2011000008273             0   0-17   F               <=0\n",
      "400    200  2011000008273             0   0-17   M               <=0\n",
      "   tract  serial_number  repeat_index num_people household_income num_vehicles\n",
      "0    200  2011000004688             0          1          <=40000            1\n",
      "1    200  2011000008273             0         4+           40000+            1\n",
      "2    200  2011000018749             0          2           40000+            1\n",
      "3    200  2011000019061             0          1           40000+            1\n",
      "4    200  2011000026513             0          2           40000+            1\n"
     ]
    }
   ],
   "source": [
    "people = population.generated_people\n",
    "households = population.generated_households\n",
    "\n",
    "sort_cols = ['tract', 'serial_number', 'repeat_index']\n",
    "\n",
    "print(people.sort_values(sort_cols).head())\n",
    "print(households.sort_values(sort_cols).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create one fat table of people and household attributes we can join on `tract`, `serial_number`, and `repeat_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tract  serial_number  repeat_index    age sex individual_income num_people  \\\n",
      "0    301  2011000003093             0  35-64   M       40000-80000         4+   \n",
      "1    301  2011000003093             0  35-64   F           100000+         4+   \n",
      "2    301  2011000003093             0   0-17   F               <=0         4+   \n",
      "3    301  2011000003093             0   0-17   M               <=0         4+   \n",
      "4    302  2011000003093             0  35-64   M       40000-80000         4+   \n",
      "\n",
      "  household_income num_vehicles  \n",
      "0           40000+            4  \n",
      "1           40000+            4  \n",
      "2           40000+            4  \n",
      "3           40000+            4  \n",
      "4           40000+            2  \n"
     ]
    }
   ],
   "source": [
    "merge_cols = ['tract', 'serial_number', 'repeat_index']\n",
    "combined = pd.merge(people, households, on=merge_cols)\n",
    "\n",
    "print(combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or write them to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "generated_people_filename = os.path.join(output_dir, 'generated_people_5year.csv')\n",
    "generated_households_filename = os.path.join(output_dir, 'generated_households_5year.csv')\n",
    "\n",
    "population.write(generated_people_filename, generated_households_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
